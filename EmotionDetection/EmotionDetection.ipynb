{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Emotion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib as plt\n",
    "import graphviz\n",
    "from pprint import pprint\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, WordPunctTokenizer, TweetTokenizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source:** Crowdflower https://www.crowdflower.com/data-for-everyone (Sentiment Analysis: Emotion in Text)\n",
    "\n",
    "**Download:** https://www.crowdflower.com/wp-content/uploads/2016/07/text_emotion.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'data/text_emotion.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "anger          110\n",
       "boredom        179\n",
       "enthusiasm     759\n",
       "empty          827\n",
       "hate          1323\n",
       "relief        1526\n",
       "fun           1776\n",
       "surprise      2187\n",
       "love          3842\n",
       "sadness       5165\n",
       "happiness     5209\n",
       "worry         8459\n",
       "neutral       8638\n",
       "Name: content, dtype: int64"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init.groupby('sentiment')['content'].count().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emotions_set = set(df_init['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger',\n",
       " 'boredom',\n",
       " 'empty',\n",
       " 'enthusiasm',\n",
       " 'fun',\n",
       " 'happiness',\n",
       " 'hate',\n",
       " 'love',\n",
       " 'neutral',\n",
       " 'relief',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'worry'}"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_emotions_list = [\n",
    "    'anger',\n",
    "#     'boredom',\n",
    "#     'empty',\n",
    "#     'enthusiasm',\n",
    "#     'fun',\n",
    "    'happiness',\n",
    "#     'hate',\n",
    "#     'love',\n",
    "#     'neutral',\n",
    "#     'relief',\n",
    "    'sadness',\n",
    "    'surprise',\n",
    "#     'worry'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_init[df_init['sentiment'].isin(keep_emotions_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_list = df.content.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of labels / emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_list = df.sentiment.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model of Emotion (Plutchik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emotions_list_plutchik = ['anger', 'anticipation', 'digust', 'fear', 'joy', 'sadness', 'surprise', 'trust']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle negations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define negations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negations_list = ['never','no','nothing','nowhere','noone','none','not','havent','hasnt','hadnt','cant',\n",
    "                  'couldnt','shouldnt','wont','wouldnt','dont','doesnt','didnt','isnt','arent','aint',\n",
    "                 'wasnt']\n",
    "\n",
    "negations_list.extend([\"haven't\",\"hasn't\",\"hadn't\",\"can't\",\"couldn't\",\"shouldn't\",\"won't\",\"wouldn't\",\n",
    "                       \"don't\",\"doesn't\",\"didn't\",\"isn't\",\"aren't\",\n",
    "                        \"wasn't\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append _NEG to every word immediately after a negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_negations(tokens):\n",
    "    new_tokens = []\n",
    "    prev_neg = False\n",
    "    for token in tokens:\n",
    "        current_token = token\n",
    "\n",
    "        if prev_neg == True:\n",
    "            current_token += \"_NEG\"\n",
    "            prev_neg = False\n",
    "\n",
    "        if token in negations_list:\n",
    "            prev_neg = True\n",
    "\n",
    "        new_tokens.append(current_token)\n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-Of Speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# universal_tags_keep = ['VERB', 'NOUN', 'ADJ']\n",
    "# VERB (verbs), NOUN (nouns), PRON (pronouns), ADJ (adjectives), ADV (adverbs), ADP (adpositions ), CONJ (conjunctions), DET (determiners), NUM (cardinal numbers), PRT (particles ), . (punctuation) and X (other)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "def custom_tokenizer(text):\n",
    "    # Tokenize text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # Handle negations\n",
    "    tokens_neg = handle_negations(tokens)\n",
    "    \n",
    "    # POS tagging\n",
    "    tokens_tagged = pos_tag(tokens, tagset='universal')\n",
    "    \n",
    "    tokens = [ (tokens_neg[i],tagged) for token in enumerate(tokens)]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_preprocessor(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|https\\S+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_options = dict(\n",
    "#     min_df = 0.1,\n",
    "#     max_df = 0.7,\n",
    "#     stop_words = 'english',\n",
    "    \n",
    "    lowercase = False,\n",
    "    tokenizer = custom_tokenizer,\n",
    "    preprocessor = custom_preprocessor,\n",
    "    ngram_range = (1, 2),\n",
    "#     binary = True\n",
    ")\n",
    "\n",
    "# vectorizer = CountVectorizer(**vectorizer_options)\n",
    "vectorizer = TfidfVectorizer(**vectorizer_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_featurevector(documents):\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "    return tfidf_matrix, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, vectorizer = create_featurevector(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12671, 104229)"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Labels / Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbl = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_target = lbl.fit_transform(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_names = lbl.classes_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_lsvc = LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Results\n",
    "- 0.54 SVM bigrams TFIDF ('anger', 'happiness', 'sadness', 'surprise', 'neutral')\n",
    "- 0.66 SVM bigrams TFIDF ('anger', 'happiness', 'sadness', 'surprise')\n",
    "- 0.67 SVM bigrams TFIDF ('anger', 'happiness', 'sadness', 'surprise') + _NEG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Mean score and 95% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.58596215  0.60015773  0.69873817  0.70268139  0.71135647  0.71428571\n",
      "  0.71507498  0.70537125  0.65323855  0.5715415 ]\n",
      "Accuracy: 0.67 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf_lsvc, train, train_target, cv=10, scoring='accuracy')\n",
    "print scores\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(clf_lsvc, train, train_target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      anger       0.00      0.00      0.00       110\n",
      "  happiness       0.68      0.78      0.73      5209\n",
      "    sadness       0.68      0.78      0.73      5165\n",
      "   surprise       0.44      0.15      0.23      2187\n",
      "\n",
      "avg / total       0.63      0.67      0.63     12671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_target, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
